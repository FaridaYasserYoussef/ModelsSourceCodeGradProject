{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjdx0UfPZx--",
        "outputId": "92971acb-56fc-47a1-b173-e0608588febe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.9 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKFslcnIaPDH",
        "outputId": "508392f2-b50d-4754-a579-e49462b03f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 36 frames for label 1\n",
            "Processed 79 frames for label 0\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# MediaPipe initialization \n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(min_detection_confidence=0.5)\n",
        "\n",
        "# Function to extract landmarks from a video frame using MediaPipe\n",
        "def extract_landmarks(frame):\n",
        "    results = holistic.process(frame)\n",
        "    if results.pose_landmarks:\n",
        "        landmarks = [[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark]\n",
        "        return landmarks\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to process and save landmarks data to JSON file\n",
        "def process_and_save_videos(video_paths, output_json_path, label):\n",
        "    data = []\n",
        "\n",
        "    for video_path in video_paths:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            landmarks = extract_landmarks(frame)\n",
        "            if landmarks is not None:\n",
        "                data.append((landmarks, label))\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "    print(f\"Processed {len(data)} frames for label {label}\")\n",
        "\n",
        "    with open(output_json_path, 'w') as json_file:\n",
        "        json.dump(data, json_file)\n",
        "\n",
        "\n",
        "# Example: Process and save positive and negative video datasets\n",
        "positive_video_paths = [\"/content/T1.mp4\", \"/content/T1.mp4\",\"/content/T2.mp4\",\"/content/T3.mp4\",\"/content/T4.mp4\",\"/content/T5.mp4\",\"/content/T6.mp4\",\"/content/T7.mp4\",\"/content/T8.mp4\",\"/content/T9.mp4\",\"/content/T10.mp4\"]\n",
        "negative_video_paths = [\"/content/N1.mp4\",\"/content/N2.mp4\",\"/content/N3.mp4\",\"/content/N4.mp4\",\"/content/N5.mp4\",\"/content/N6.mp4\",]\n",
        "\n",
        "process_and_save_videos(positive_video_paths, \"positive_data.json\", label=1)\n",
        "process_and_save_videos(negative_video_paths, \"negative_data.json\", label=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH3vgm2agg8D",
        "outputId": "2e226951-994e-4bc3-e153-88994c560fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9130434782608695\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data from JSON files\n",
        "with open(\"/content/positive_data.json\", 'r') as json_file:\n",
        "    positive_data = json.load(json_file)\n",
        "\n",
        "with open(\"/content/negative_data.json\", 'r') as json_file:\n",
        "    negative_data = json.load(json_file)\n",
        "\n",
        "# Combine positive and negative data\n",
        "all_data = positive_data + negative_data\n",
        "\n",
        "# Separate features (landmarks) and labels\n",
        "X = [item[0] for item in all_data]\n",
        "y = [item[1] for item in all_data]\n",
        "\n",
        "# Flatten the features array\n",
        "X_flat = [item for sublist in X for item in sublist]\n",
        "\n",
        "# Convert to NumPy array\n",
        "X_flat_array = np.array(X_flat)\n",
        "\n",
        "# Reshape X_flat_array to match the number of labels\n",
        "X_flat_array = X_flat_array.reshape(len(y), -1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat_array, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the RandomForestClassifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-1LwZCvimHh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
