{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Module for data-related stuff.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class DrivingDataset:\n",
    "\n",
    "    CLASSES = {\n",
    "        \"speedbumppassing\": \"speedbumppassing\",\n",
    "        \"zigzag\": \"zigzag\",\n",
    "    }\n",
    "\n",
    "    FEATURES = [\n",
    "        \"ax\",\n",
    "        \"ay\",\n",
    "        \"az\",\n",
    "        \"wx\",\n",
    "        \"wy\",\n",
    "        \"wz\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, data_root, unwrapped_attitude=False,\n",
    "                 metadata_file=None):\n",
    "        self.data_root = pathlib.Path(data_root)\n",
    "        self.files = []\n",
    "        self.unwrapped_attitude = unwrapped_attitude\n",
    "        self.metadata = {}  # Dictionary with participant codes as keys.\n",
    "\n",
    "        # Save each CSV file and infer class from filename.\n",
    "        for csv_ in self.data_root.glob(\"**/*.csv\"):\n",
    "            class_ = str(csv_.parent.stem)[:3]\n",
    "            if class_ in self.CLASSES.keys():\n",
    "                self.files.append([csv_, class_])\n",
    "\n",
    "        # Read metadata form given file.\n",
    "        if metadata_file:\n",
    "            with open(metadata_file, newline=\"\") as metadata:\n",
    "                csv_reader = csv.reader(metadata)\n",
    "                next(csv_reader, None)  # skip the headers\n",
    "                for row in csv_reader:\n",
    "                    self.metadata[row[0]] = list(map(int, row[1:]))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        file_, class_ = self.files[item]\n",
    "        signals = csv2numpy(file_)\n",
    "\n",
    "        if self.unwrapped_attitude:\n",
    "            # Unwrap attitude signals.\n",
    "            for i in range(3):\n",
    "                signals[:, i] = np.unwrap(signals[:, i])\n",
    "\n",
    "        if self.metadata:\n",
    "            # Read metadata and return as extra element.\n",
    "            metadata = self.metadata[file_.stem.split(\"_\")[1]]\n",
    "            return signals, class_, metadata\n",
    "        return signals, class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "class HARDatasetCrops(HARDataset):\n",
    "    \"\"\"Dataset with fixed-length crops.\n",
    "\n",
    "    Args:\n",
    "        data_root -- string. Path to data directory.\n",
    "        length -- int. Crops length.\n",
    "        discard_start -- int. Number of samples to discard from start.\n",
    "        discard_end -- int. Number of samples to discard from end.\n",
    "        unwrapped_attitude -- bool. Whether to unwrap attitude signals.\n",
    "        padding_mode -- None or string. If None, the samples not fitting in\n",
    "                integer number of windows will be discarded. If string,\n",
    "                the value will be passed to numpy's pad function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_root, length, discard_start, discard_end,\n",
    "                 unwrapped_attitude=True, padding_mode=None,\n",
    "                 metadata_file=None):\n",
    "        super().__init__(data_root, unwrapped_attitude=unwrapped_attitude,\n",
    "                         metadata_file=metadata_file)\n",
    "        self.length = length\n",
    "        self.discard_start = discard_start\n",
    "        self.discard_end = discard_end\n",
    "        self.padding_mode = padding_mode\n",
    "\n",
    "        self.crops = self.get_crops()\n",
    "\n",
    "    def get_crops(self):\n",
    "        \"\"\"Return list with crops from files.\"\"\"\n",
    "        crops = []\n",
    "        # Iterate over data files.\n",
    "        for file, class_ in self.files:\n",
    "            # Read from file.\n",
    "            signal = csv2numpy(file)\n",
    "            # Crop start and end.\n",
    "            signal = signal[self.discard_start:(signal.shape[0] - self.discard_end)]\n",
    "            windows, remainder = divmod(signal.shape[0], self.length)\n",
    "            if self.padding_mode and remainder != 0:\n",
    "                # Apply padding with given padding mode.\n",
    "                padding = self.length * (windows + 1) - signal.shape[0]\n",
    "                signal = np.pad(signal, ((0, padding), (0, 0)), self.padding_mode)\n",
    "            elif self.padding_mode is None:\n",
    "                # Crop the end.\n",
    "                signal = signal[:(self.length * windows)]\n",
    "            # Obtain crops from <discard_start> to <discard-end>.\n",
    "            for i in range(0, signal.shape[0], self.length):\n",
    "                crop = signal[i:(i + self.length)]\n",
    "                if self.unwrapped_attitude:\n",
    "                    # Unwrap phase of first 3 features (attitude signals).\n",
    "                    for s in range(3):\n",
    "                        crop[:, s] = np.unwrap(crop[:, s])\n",
    "                if self.metadata:\n",
    "                    # Read metadata and return as extra element.\n",
    "                    metadata = self.metadata[file.stem.split(\"_\")[1]]\n",
    "                    crops.append([crop, class_, metadata])\n",
    "                else:\n",
    "                    crops.append([crop, class_])\n",
    "\n",
    "        return crops\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.crops[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.crops)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = HARDatasetCrops('motionsense-dataset', 256, 10, 10, True)\n",
    "    for item in iter(dataset):\n",
    "        assert item[0].shape == (256, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c19e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, concatenate, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f38f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files_train = []\n",
    "for i in os.listdir(\"zigzag/train\"):\n",
    "    files_train.append([\"zigzag/train/\"+i, \"zigzag\"])\n",
    "    \n",
    "    \n",
    "for i in os.listdir(\"speedbumppassing/train\"):\n",
    "    files_train.append([\"speedbumppassing/train/\"+i, \"speedbump\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f72ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files_test = []\n",
    "for i in os.listdir(\"zigzag/test\"):\n",
    "    files_test.append([\"zigzag/test/\"+i, \"zigzag\"])\n",
    "    \n",
    "    \n",
    "for i in os.listdir(\"speedbumppassing/test\"):\n",
    "    files_test.append([\"speedbumppassing/test/\"+i, \"speedbump\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28211323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def csv2numpy(file_name):\n",
    "    \"\"\"Read multidimensional signal from file\"\"\"\n",
    "    # Read data from file.\n",
    "    data = np.genfromtxt(file_name, delimiter=\",\", skip_header=1)\n",
    "    # Return all columns but the first one (as it is the index).\n",
    "    return data[:, 1:-1]\n",
    "\n",
    "\n",
    "\n",
    "def get_crops(files, length, discard_start, discard_end, padding_mode=None):\n",
    "        \"\"\"Return list with crops from files.\"\"\"\n",
    "        crops = []\n",
    "        # Iterate over data files.\n",
    "        for file, class_ in files:\n",
    "            # Read from file.\n",
    "            signal = csv2numpy(file)\n",
    "            # Crop start and end.\n",
    "            signal = signal[discard_start:(signal.shape[0] - discard_end)]\n",
    "            windows, remainder = divmod(signal.shape[0], length)\n",
    "            if padding_mode and remainder != 0:\n",
    "                # Apply padding with given padding mode.\n",
    "                padding = length * (windows + 1) - signal.shape[0]\n",
    "                signal = np.pad(signal, ((0, padding), (0, 0)), padding_mode)\n",
    "            elif padding_mode is None:\n",
    "                # Crop the end.\n",
    "                signal = signal[:(length * windows)]\n",
    "            # Obtain crops from <discard_start> to <discard-end>.\n",
    "            for i in range(0, signal.shape[0], length):\n",
    "                crop = signal[i:(i + length)]\n",
    "                crops.append([crop, class_])\n",
    "\n",
    "        return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60604054",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_train = get_crops(files_train, 245, 50, 50)\n",
    "crops_test = get_crops(files_test, 245, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c57c105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "label_encoder.fit([\"zigzag\", \"speedbump\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d009d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in crops_train:\n",
    "    X_train.append(i[0])\n",
    "    y_train.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28c1f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for i in crops_test:\n",
    "    X_test.append(i[0])\n",
    "    y_test.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fc4c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b6bc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(label_encoder.transform(y_train))\n",
    "y_test = to_categorical(label_encoder.transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f332a360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15938, 245, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78ba58",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e52dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Sequential()\n",
    "#add model layers\n",
    "clf.add(Conv1D(16, kernel_size=5, activation=\"relu\", input_shape=(245, 6)))\n",
    "clf.add(Conv1D(32, kernel_size=5, activation=\"relu\"))\n",
    "clf.add(Flatten())\n",
    "clf.add(Dense(2, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91740318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "499/499 [==============================] - 9s 13ms/step - loss: 0.1537 - accuracy: 0.9585 - val_loss: 1.0717 - val_accuracy: 0.8261\n",
      "Epoch 2/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0974 - accuracy: 0.9674 - val_loss: 1.2905 - val_accuracy: 0.8290\n",
      "Epoch 3/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0688 - accuracy: 0.9792 - val_loss: 1.3690 - val_accuracy: 0.7942\n",
      "Epoch 4/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0484 - accuracy: 0.9893 - val_loss: 1.2045 - val_accuracy: 0.7420\n",
      "Epoch 5/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0393 - accuracy: 0.9916 - val_loss: 1.0115 - val_accuracy: 0.8478\n",
      "Epoch 6/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0367 - accuracy: 0.9922 - val_loss: 1.0720 - val_accuracy: 0.8377\n",
      "Epoch 7/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0364 - accuracy: 0.9930 - val_loss: 1.4611 - val_accuracy: 0.8536\n",
      "Epoch 8/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0321 - accuracy: 0.9939 - val_loss: 1.1174 - val_accuracy: 0.8522\n",
      "Epoch 9/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0287 - accuracy: 0.9945 - val_loss: 1.2905 - val_accuracy: 0.8565\n",
      "Epoch 10/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0446 - accuracy: 0.9924 - val_loss: 1.7829 - val_accuracy: 0.8449\n",
      "Epoch 11/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0236 - accuracy: 0.9972 - val_loss: 1.4067 - val_accuracy: 0.8551\n",
      "Epoch 12/30\n",
      "499/499 [==============================] - 6s 11ms/step - loss: 0.0240 - accuracy: 0.9962 - val_loss: 1.5729 - val_accuracy: 0.8464\n",
      "Epoch 13/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0230 - accuracy: 0.9967 - val_loss: 1.4501 - val_accuracy: 0.8246\n",
      "Epoch 14/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0264 - accuracy: 0.9955 - val_loss: 1.6469 - val_accuracy: 0.8522\n",
      "Epoch 15/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 1.5249 - val_accuracy: 0.8609\n",
      "Epoch 16/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0267 - accuracy: 0.9960 - val_loss: 1.6153 - val_accuracy: 0.8362\n",
      "Epoch 17/30\n",
      "499/499 [==============================] - 6s 11ms/step - loss: 0.0198 - accuracy: 0.9972 - val_loss: 2.0442 - val_accuracy: 0.8261\n",
      "Epoch 18/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0272 - accuracy: 0.9957 - val_loss: 1.7400 - val_accuracy: 0.8507\n",
      "Epoch 19/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0198 - accuracy: 0.9976 - val_loss: 1.7945 - val_accuracy: 0.8507\n",
      "Epoch 20/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0219 - accuracy: 0.9969 - val_loss: 2.5289 - val_accuracy: 0.8435\n",
      "Epoch 21/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0292 - accuracy: 0.9963 - val_loss: 1.2403 - val_accuracy: 0.8464\n",
      "Epoch 22/30\n",
      "499/499 [==============================] - 6s 11ms/step - loss: 0.0180 - accuracy: 0.9977 - val_loss: 1.6771 - val_accuracy: 0.8435\n",
      "Epoch 23/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0213 - accuracy: 0.9965 - val_loss: 2.2558 - val_accuracy: 0.8478\n",
      "Epoch 24/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0186 - accuracy: 0.9976 - val_loss: 1.8725 - val_accuracy: 0.8507\n",
      "Epoch 25/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0215 - accuracy: 0.9968 - val_loss: 2.0819 - val_accuracy: 0.8478\n",
      "Epoch 26/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0192 - accuracy: 0.9975 - val_loss: 2.4160 - val_accuracy: 0.8478\n",
      "Epoch 27/30\n",
      "499/499 [==============================] - 6s 12ms/step - loss: 0.0176 - accuracy: 0.9978 - val_loss: 2.3333 - val_accuracy: 0.8478\n",
      "Epoch 28/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 1.9338 - val_accuracy: 0.8507\n",
      "Epoch 29/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0144 - accuracy: 0.9981 - val_loss: 2.4468 - val_accuracy: 0.8507\n",
      "Epoch 30/30\n",
      "499/499 [==============================] - 6s 13ms/step - loss: 0.0205 - accuracy: 0.9971 - val_loss: 2.0185 - val_accuracy: 0.8478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x228c8c39890>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a27d6d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 6ms/step - loss: 1.2629 - accuracy: 0.8159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2629058361053467, 0.8159420490264893]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba05b00",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b11cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "#Splitting data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Building Transformer\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "40455572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3019cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(2, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "72514aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 245, 6)]             0         []                            \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 245, 6)               222       ['input_5[0][0]',             \n",
      " ltiHeadAttention)                                                   'input_5[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)        (None, 245, 6)               0         ['multi_head_attention_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 245, 6)               12        ['dropout_26[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (None, 245, 6)               0         ['layer_normalization_16[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'input_5[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)          (None, 245, 3)               21        ['tf.__operators__.add_16[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)        (None, 245, 3)               0         ['conv1d_28[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)          (None, 245, 6)               24        ['dropout_27[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 245, 6)               12        ['conv1d_29[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (None, 245, 6)               0         ['layer_normalization_17[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_16[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, 245, 6)               222       ['tf.__operators__.add_17[0][0\n",
      " ltiHeadAttention)                                                  ]',                           \n",
      "                                                                     'tf.__operators__.add_17[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)        (None, 245, 6)               0         ['multi_head_attention_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, 245, 6)               12        ['dropout_28[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (None, 245, 6)               0         ['layer_normalization_18[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_17[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)          (None, 245, 3)               21        ['tf.__operators__.add_18[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)        (None, 245, 3)               0         ['conv1d_30[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)          (None, 245, 6)               24        ['dropout_29[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, 245, 6)               12        ['conv1d_31[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (None, 245, 6)               0         ['layer_normalization_19[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_18[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (None, 245, 6)               222       ['tf.__operators__.add_19[0][0\n",
      " ultiHeadAttention)                                                 ]',                           \n",
      "                                                                     'tf.__operators__.add_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 245, 6)               0         ['multi_head_attention_10[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_20 (La  (None, 245, 6)               12        ['dropout_30[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (None, 245, 6)               0         ['layer_normalization_20[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)          (None, 245, 3)               21        ['tf.__operators__.add_20[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_31 (Dropout)        (None, 245, 3)               0         ['conv1d_32[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)          (None, 245, 6)               24        ['dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_21 (La  (None, 245, 6)               12        ['conv1d_33[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (None, 245, 6)               0         ['layer_normalization_21[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_20[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (M  (None, 245, 6)               222       ['tf.__operators__.add_21[0][0\n",
      " ultiHeadAttention)                                                 ]',                           \n",
      "                                                                     'tf.__operators__.add_21[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)        (None, 245, 6)               0         ['multi_head_attention_11[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_22 (La  (None, 245, 6)               12        ['dropout_32[0][0]']          \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (None, 245, 6)               0         ['layer_normalization_22[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_21[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)          (None, 245, 3)               21        ['tf.__operators__.add_22[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)        (None, 245, 3)               0         ['conv1d_34[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)          (None, 245, 6)               24        ['dropout_33[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_23 (La  (None, 245, 6)               12        ['conv1d_35[0][0]']           \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (None, 245, 6)               0         ['layer_normalization_23[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_22[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 245)                  0         ['tf.__operators__.add_23[0][0\n",
      "  (GlobalAveragePooling1D)                                          ]']                           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 128)                  31488     ['global_average_pooling1d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)        (None, 128)                  0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 2)                    258       ['dropout_34[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32910 (128.55 KB)\n",
      "Trainable params: 32910 (128.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 242s 929ms/step - loss: 0.3279 - categorical_accuracy: 0.8901 - val_loss: 0.6221 - val_categorical_accuracy: 0.8145\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 238s 951ms/step - loss: 0.1834 - categorical_accuracy: 0.9543 - val_loss: 0.6991 - val_categorical_accuracy: 0.8159\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 246s 985ms/step - loss: 0.1457 - categorical_accuracy: 0.9565 - val_loss: 0.7928 - val_categorical_accuracy: 0.8174\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 242s 966ms/step - loss: 0.1297 - categorical_accuracy: 0.9575 - val_loss: 0.8759 - val_categorical_accuracy: 0.8116\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 246s 985ms/step - loss: 0.1213 - categorical_accuracy: 0.9584 - val_loss: 0.9076 - val_categorical_accuracy: 0.8203\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 257s 1s/step - loss: 0.1144 - categorical_accuracy: 0.9589 - val_loss: 0.8908 - val_categorical_accuracy: 0.8217\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 260s 1s/step - loss: 0.1093 - categorical_accuracy: 0.9603 - val_loss: 0.9606 - val_categorical_accuracy: 0.8217\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 261s 1s/step - loss: 0.1058 - categorical_accuracy: 0.9598 - val_loss: 1.0146 - val_categorical_accuracy: 0.8217\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 250s 1s/step - loss: 0.1031 - categorical_accuracy: 0.9608 - val_loss: 1.0171 - val_categorical_accuracy: 0.8232\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 250s 1s/step - loss: 0.0995 - categorical_accuracy: 0.9612 - val_loss: 1.0176 - val_categorical_accuracy: 0.8217\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 256s 1s/step - loss: 0.0972 - categorical_accuracy: 0.9612 - val_loss: 1.0607 - val_categorical_accuracy: 0.8217\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 250s 1s/step - loss: 0.0927 - categorical_accuracy: 0.9629 - val_loss: 1.0511 - val_categorical_accuracy: 0.8246\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 246s 983ms/step - loss: 0.0897 - categorical_accuracy: 0.9632 - val_loss: 1.1039 - val_categorical_accuracy: 0.8217\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 252s 1s/step - loss: 0.0856 - categorical_accuracy: 0.9637 - val_loss: 1.1134 - val_categorical_accuracy: 0.8217\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 249s 996ms/step - loss: 0.0830 - categorical_accuracy: 0.9642 - val_loss: 1.0346 - val_categorical_accuracy: 0.8232\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 244s 975ms/step - loss: 0.0809 - categorical_accuracy: 0.9654 - val_loss: 1.1368 - val_categorical_accuracy: 0.8217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "250/250 [==============================] - 247s 988ms/step - loss: 0.0771 - categorical_accuracy: 0.9662 - val_loss: 1.1839 - val_categorical_accuracy: 0.8217\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 252s 1s/step - loss: 0.0770 - categorical_accuracy: 0.9678 - val_loss: 1.1912 - val_categorical_accuracy: 0.8203\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 287s 1s/step - loss: 0.0716 - categorical_accuracy: 0.9679 - val_loss: 1.1417 - val_categorical_accuracy: 0.8217\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 266s 1s/step - loss: 0.0720 - categorical_accuracy: 0.9693 - val_loss: 1.1724 - val_categorical_accuracy: 0.8188\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 253s 1s/step - loss: 0.0672 - categorical_accuracy: 0.9709 - val_loss: 1.2393 - val_categorical_accuracy: 0.8232\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 255s 1s/step - loss: 0.0655 - categorical_accuracy: 0.9720 - val_loss: 1.1618 - val_categorical_accuracy: 0.8203\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 248s 992ms/step - loss: 0.0656 - categorical_accuracy: 0.9719 - val_loss: 1.2699 - val_categorical_accuracy: 0.8217\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 247s 986ms/step - loss: 0.0611 - categorical_accuracy: 0.9740 - val_loss: 1.2353 - val_categorical_accuracy: 0.8203\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 242s 967ms/step - loss: 0.0625 - categorical_accuracy: 0.9734 - val_loss: 1.2450 - val_categorical_accuracy: 0.8217\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 240s 960ms/step - loss: 0.0601 - categorical_accuracy: 0.9747 - val_loss: 1.3277 - val_categorical_accuracy: 0.8188\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 239s 956ms/step - loss: 0.0564 - categorical_accuracy: 0.9749 - val_loss: 1.3222 - val_categorical_accuracy: 0.8232\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 246s 984ms/step - loss: 0.0557 - categorical_accuracy: 0.9756 - val_loss: 1.2950 - val_categorical_accuracy: 0.8217\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 266s 1s/step - loss: 0.0530 - categorical_accuracy: 0.9782 - val_loss: 1.2998 - val_categorical_accuracy: 0.8232\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 255s 1s/step - loss: 0.0513 - categorical_accuracy: 0.9785 - val_loss: 1.3917 - val_categorical_accuracy: 0.8232\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 251s 1s/step - loss: 0.0516 - categorical_accuracy: 0.9787 - val_loss: 1.3750 - val_categorical_accuracy: 0.8203\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 260s 1s/step - loss: 0.0491 - categorical_accuracy: 0.9795 - val_loss: 1.3386 - val_categorical_accuracy: 0.8203\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 240s 962ms/step - loss: 0.0487 - categorical_accuracy: 0.9802 - val_loss: 1.4175 - val_categorical_accuracy: 0.8217\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 246s 985ms/step - loss: 0.0455 - categorical_accuracy: 0.9814 - val_loss: 1.4374 - val_categorical_accuracy: 0.8217\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 253s 1s/step - loss: 0.0451 - categorical_accuracy: 0.9815 - val_loss: 1.4086 - val_categorical_accuracy: 0.8188\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 242s 970ms/step - loss: 0.0431 - categorical_accuracy: 0.9826 - val_loss: 1.4216 - val_categorical_accuracy: 0.8203\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 238s 954ms/step - loss: 0.0420 - categorical_accuracy: 0.9832 - val_loss: 1.4343 - val_categorical_accuracy: 0.8188\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 248s 991ms/step - loss: 0.0422 - categorical_accuracy: 0.9824 - val_loss: 1.4433 - val_categorical_accuracy: 0.8203\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 248s 994ms/step - loss: 0.0386 - categorical_accuracy: 0.9859 - val_loss: 1.5221 - val_categorical_accuracy: 0.8232\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 243s 974ms/step - loss: 0.0387 - categorical_accuracy: 0.9850 - val_loss: 1.4221 - val_categorical_accuracy: 0.8188\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 243s 973ms/step - loss: 0.0369 - categorical_accuracy: 0.9855 - val_loss: 1.5500 - val_categorical_accuracy: 0.8232\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 246s 985ms/step - loss: 0.0350 - categorical_accuracy: 0.9856 - val_loss: 1.5256 - val_categorical_accuracy: 0.8217\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 244s 975ms/step - loss: 0.0346 - categorical_accuracy: 0.9870 - val_loss: 1.5494 - val_categorical_accuracy: 0.8217\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 244s 975ms/step - loss: 0.0340 - categorical_accuracy: 0.9872 - val_loss: 1.5993 - val_categorical_accuracy: 0.8203\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 244s 978ms/step - loss: 0.0330 - categorical_accuracy: 0.9877 - val_loss: 1.6406 - val_categorical_accuracy: 0.8217\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 248s 992ms/step - loss: 0.0323 - categorical_accuracy: 0.9882 - val_loss: 1.6081 - val_categorical_accuracy: 0.8203\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 236s 945ms/step - loss: 0.0322 - categorical_accuracy: 0.9896 - val_loss: 1.5962 - val_categorical_accuracy: 0.8217\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 238s 952ms/step - loss: 0.0301 - categorical_accuracy: 0.9903 - val_loss: 1.6883 - val_categorical_accuracy: 0.8203\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 236s 943ms/step - loss: 0.0305 - categorical_accuracy: 0.9896 - val_loss: 1.6137 - val_categorical_accuracy: 0.8159\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 239s 956ms/step - loss: 0.0280 - categorical_accuracy: 0.9905 - val_loss: 1.6726 - val_categorical_accuracy: 0.8159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x228cb924d10>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=2,\n",
    "    num_heads=4,\n",
    "    ff_dim=3,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.3,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "#     callbacks=callbacks,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "201992a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 3s 146ms/step - loss: 1.6726 - categorical_accuracy: 0.8159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6725695133209229, 0.8159420490264893]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c72ba",
   "metadata": {},
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2886127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "499/499 [==============================] - 123s 236ms/step - loss: 0.3693 - accuracy: 0.9558 - val_loss: 1.1027 - val_accuracy: 0.8174\n",
      "Epoch 2/100\n",
      "499/499 [==============================] - 118s 237ms/step - loss: 0.1883 - accuracy: 0.9570 - val_loss: 0.9251 - val_accuracy: 0.8174\n",
      "Epoch 3/100\n",
      "499/499 [==============================] - 121s 242ms/step - loss: 0.1766 - accuracy: 0.9570 - val_loss: 1.3178 - val_accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "499/499 [==============================] - 122s 245ms/step - loss: 0.1852 - accuracy: 0.9570 - val_loss: 0.7773 - val_accuracy: 0.8174\n",
      "Epoch 5/100\n",
      "499/499 [==============================] - 125s 251ms/step - loss: 0.1745 - accuracy: 0.9570 - val_loss: 0.6431 - val_accuracy: 0.8174\n",
      "Epoch 6/100\n",
      "499/499 [==============================] - 126s 252ms/step - loss: 0.1806 - accuracy: 0.9570 - val_loss: 0.7307 - val_accuracy: 0.8174\n",
      "Epoch 7/100\n",
      "499/499 [==============================] - 126s 253ms/step - loss: 0.1687 - accuracy: 0.9570 - val_loss: 0.9165 - val_accuracy: 0.8174\n",
      "Epoch 8/100\n",
      "499/499 [==============================] - 124s 248ms/step - loss: 0.1726 - accuracy: 0.9570 - val_loss: 0.7605 - val_accuracy: 0.8174\n",
      "Epoch 9/100\n",
      "458/499 [==========================>...] - ETA: 10s - loss: 0.1814 - accuracy: 0.9581"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define the model with L2 regularization\n",
    "model = Sequential()\n",
    "\n",
    "# TimeDistributed(Conv1D()) layer with parameters and L2 regularization\n",
    "model.add(TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)), input_shape=(245, 6, 1)))\n",
    "\n",
    "# TimeDistributed(MaxPooling1D()) layer with parameters and padding\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2, padding='same')))\n",
    "\n",
    "# TimeDistributed(Conv1D()) layer with parameters and L2 regularization\n",
    "model.add(TimeDistributed(Conv1D(filters=8, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.01))))\n",
    "\n",
    "# TimeDistributed(MaxPooling1D()) layer with parameters and padding\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2, padding='same')))\n",
    "\n",
    "# TimeDistributed(Conv1D()) layer with parameters and L2 regularization\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.01))))\n",
    "\n",
    "# TimeDistributed(MaxPooling1D()) layer with parameters and padding\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2, padding='same')))\n",
    "\n",
    "# TimeDistributed(Conv1D()) layer with parameters and L2 regularization\n",
    "model.add(TimeDistributed(Conv1D(filters=8, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.01))))\n",
    "\n",
    "# TimeDistributed(MaxPooling1D()) layer with parameters and padding\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2, padding='same')))\n",
    "\n",
    "# TimeDistributed(Flatten()) layer\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# Define LSTM model with parameters and L2 regularization\n",
    "model.add(LSTM(units=60, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Additional LSTM layer with L2 regularization\n",
    "model.add(LSTM(units=70, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
    "\n",
    "# Flatten layer outside TimeDistributed\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layer with parameters and L2 regularization\n",
    "model.add(Dense(units=2, activation='sigmoid', kernel_regularizer=l2(0.01)))  # Adjust units to match the number of output classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c60ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 66ms/step - loss: 1.0679 - accuracy: 0.8174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.067910075187683, 0.8173912763595581]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cebbce9",
   "metadata": {},
   "source": [
    "# TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "278275e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tcn\n",
      "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras-tcn) (1.24.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras-tcn) (2.14.0)\n",
      "Collecting tensorflow-addons (from keras-tcn)\n",
      "  Obtaining dependency information for tensorflow-addons from https://files.pythonhosted.org/packages/ec/52/047d768c4669db0c059109a88c21a3c71bcda957c46f13967e44b8c7fa4c/tensorflow_addons-0.22.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_addons-0.22.0-cp311-cp311-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow->keras-tcn) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.14.0)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->keras-tcn)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow->keras-tcn) (3.2.2)\n",
      "Downloading tensorflow_addons-0.22.0-cp311-cp311-win_amd64.whl (719 kB)\n",
      "   ---------------------------------------- 0.0/719.8 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/719.8 kB 660.6 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 92.2/719.8 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 204.8/719.8 kB 1.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 307.2/719.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 440.3/719.8 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 583.7/719.8 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  716.8/719.8 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 719.8/719.8 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: typeguard, tensorflow-addons, keras-tcn\n",
      "Successfully installed keras-tcn-3.5.0 tensorflow-addons-0.22.0 typeguard-2.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: neuralplot 0.0.8 has a non-standard dependency specifier matplotlib>=3.1numpy>=1.16. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of neuralplot or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1880de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 64)                88128     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88258 (344.76 KB)\n",
      "Trainable params: 88258 (344.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "499/499 [==============================] - 42s 79ms/step - loss: 0.1641 - accuracy: 0.9578 - val_loss: 2.0508 - val_accuracy: 0.8130\n",
      "Epoch 2/50\n",
      "499/499 [==============================] - 40s 80ms/step - loss: 0.0793 - accuracy: 0.9707 - val_loss: 2.6754 - val_accuracy: 0.8101\n",
      "Epoch 3/50\n",
      "499/499 [==============================] - 41s 82ms/step - loss: 0.0675 - accuracy: 0.9762 - val_loss: 4.6334 - val_accuracy: 0.8145\n",
      "Epoch 4/50\n",
      "499/499 [==============================] - 42s 84ms/step - loss: 0.0435 - accuracy: 0.9834 - val_loss: 5.7472 - val_accuracy: 0.8217\n",
      "Epoch 5/50\n",
      "499/499 [==============================] - 42s 83ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 7.0643 - val_accuracy: 0.8232\n",
      "Epoch 6/50\n",
      "499/499 [==============================] - 42s 84ms/step - loss: 0.0204 - accuracy: 0.9928 - val_loss: 5.5956 - val_accuracy: 0.8217\n",
      "Epoch 7/50\n",
      "499/499 [==============================] - 42s 85ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 6.4303 - val_accuracy: 0.8232\n",
      "Epoch 8/50\n",
      "499/499 [==============================] - 42s 84ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 7.0053 - val_accuracy: 0.8203\n",
      "Epoch 9/50\n",
      "499/499 [==============================] - 42s 83ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 4.7507 - val_accuracy: 0.8145\n",
      "Epoch 10/50\n",
      "499/499 [==============================] - 44s 88ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 7.7313 - val_accuracy: 0.8188\n",
      "Epoch 11/50\n",
      "499/499 [==============================] - 43s 86ms/step - loss: 8.1932e-04 - accuracy: 0.9999 - val_loss: 11.5342 - val_accuracy: 0.8232\n",
      "Epoch 12/50\n",
      "499/499 [==============================] - 44s 88ms/step - loss: 1.3767e-04 - accuracy: 1.0000 - val_loss: 11.5978 - val_accuracy: 0.8246\n",
      "Epoch 13/50\n",
      "499/499 [==============================] - 44s 87ms/step - loss: 3.1531e-05 - accuracy: 1.0000 - val_loss: 11.6139 - val_accuracy: 0.8246\n",
      "Epoch 14/50\n",
      "499/499 [==============================] - 44s 89ms/step - loss: 1.8233e-05 - accuracy: 1.0000 - val_loss: 11.7301 - val_accuracy: 0.8246\n",
      "Epoch 15/50\n",
      "499/499 [==============================] - 44s 88ms/step - loss: 1.2064e-05 - accuracy: 1.0000 - val_loss: 11.9139 - val_accuracy: 0.8246\n",
      "Epoch 16/50\n",
      "499/499 [==============================] - 45s 90ms/step - loss: 6.7389e-06 - accuracy: 1.0000 - val_loss: 12.4121 - val_accuracy: 0.8246\n",
      "Epoch 17/50\n",
      "499/499 [==============================] - 43s 86ms/step - loss: 3.1208e-06 - accuracy: 1.0000 - val_loss: 13.0405 - val_accuracy: 0.8232\n",
      "Epoch 18/50\n",
      " 93/499 [====>.........................] - ETA: 35s - loss: 2.0752e-06 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 27\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     28\u001b[0m     X_train,\n\u001b[0;32m     29\u001b[0m     y_train,\n\u001b[0;32m     30\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     31\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     32\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#     callbacks=[early_stopping]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build TCN Model\n",
    "from tcn import TCN\n",
    "def build_tcn_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Add TCN layer\n",
    "    model.add(TCN(input_shape=input_shape, nb_filters=64, kernel_size=3, dilations=[1, 2, 4, 8], return_sequences=False))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_shape = X_train.shape[1:]\n",
    "model = build_tcn_model(input_shape, 2)\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the Model\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "#     callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "438fe0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 28ms/step - loss: 13.1033 - accuracy: 0.8246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.103269577026367, 0.8246376514434814]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ee889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
